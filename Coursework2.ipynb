{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JGrant3101/ME4MachineLearning/blob/main/Coursework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will start by importing all the libraries which might need to be used."
      ],
      "metadata": {
        "id": "z6KH25qmc006"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CTrRPkLkcx-l"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn import model_selection\n",
        "from sklearn import naive_bayes\n",
        "from sklearn import linear_model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas\n",
        "import plotly.graph_objects as go\n",
        "import sys\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Firstly going to build the neural network for dataset1"
      ],
      "metadata": {
        "id": "ngshmKkneNDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by importing the dataset\n",
        "dataset1 = pandas.read_csv('/content/dataset1.csv')\n",
        "\n",
        "# Write each column of the file to an array to make it easier to work with\n",
        "ArmLength1 = np.array(dataset1['Arm length (m)'][:])\n",
        "BallWeight1 = np.array(dataset1['Ball weight (kg)'][:])\n",
        "BallRadius1 = np.array(dataset1['Ball radius (mm)'][:])\n",
        "AirTemp1 = np.array(dataset1['Air temperature (deg C)'][:])\n",
        "SpringConst1 = np.array(dataset1['Spring constant (N per m)'][:])\n",
        "DeviceWeight1 = np.array(dataset1['Device weight (kg)'][:])\n",
        "TargetHit1 = np.array(dataset1['Target hit'][:])\n",
        "# Converting our currently 1D y values to 2D to match our model\n",
        "TargetHit1_binary = to_categorical(TargetHit1)\n",
        "\n",
        "# Going to scale each all of the data so want to find the mean and standard deviation\n",
        "ArmLength1Mean = np.mean(ArmLength1)\n",
        "ArmLength1std = np.std(ArmLength1)\n",
        "BallWeight1Mean = np.mean(BallWeight1)\n",
        "BallWeight1std = np.std(BallWeight1)\n",
        "BallRadius1Mean = np.mean(BallRadius1)\n",
        "BallRadius1std = np.std(BallRadius1)\n",
        "AirTemp1Mean = np.mean(AirTemp1)\n",
        "AirTemp1std = np.std(AirTemp1)\n",
        "SpringConst1Mean = np.mean(SpringConst1)\n",
        "SpringConst1std = np.std(SpringConst1)\n",
        "DeviceWeight1Mean = np.mean(DeviceWeight1)\n",
        "DeviceWeight1std = np.std(DeviceWeight1)\n",
        "\n",
        "# Finally creating the scaled arrays using these mean and std values\n",
        "ArmLength1Scaled = (ArmLength1 - ArmLength1Mean)/ArmLength1std\n",
        "BallWeight1Scaled = (BallWeight1 - BallWeight1Mean)/BallWeight1std\n",
        "BallRadius1Scaled = (BallRadius1 - BallRadius1Mean)/BallRadius1std\n",
        "AirTemp1Scaled = (AirTemp1 - AirTemp1Mean)/AirTemp1std\n",
        "SpringConst1Scaled = (SpringConst1 - SpringConst1Mean)/SpringConst1std\n",
        "DeviceWeight1Scaled = (DeviceWeight1 - DeviceWeight1Mean)/DeviceWeight1std\n",
        "\n",
        "# Finally forming these into one array to be parsed into the fit function\n",
        "Inputs1 = np.zeros((2000, 6))\n",
        "Inputs1[:,0] = ArmLength1Scaled\n",
        "Inputs1[:,1] = BallWeight1Scaled\n",
        "Inputs1[:,2] = BallRadius1Scaled\n",
        "Inputs1[:,3] = AirTemp1Scaled\n",
        "Inputs1[:,4] = SpringConst1Scaled\n",
        "Inputs1[:,5] = DeviceWeight1Scaled"
      ],
      "metadata": {
        "id": "95wNeH_peRL4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above we have imported and processed our input data to be used to train the network"
      ],
      "metadata": {
        "id": "W6NruT16jp0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now will do the actual construction of the network"
      ],
      "metadata": {
        "id": "5leFeJ55jwwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising our neural network\n",
        "model1 = Sequential()\n",
        "\n",
        "# Adding layers, these layers are two layers of 4 nodes using the ReLU function and 1 with 2 nodes using the softmax function\n",
        "model1.add(Dense(units = 10, activation = 'relu', input_dim = 6))\n",
        "model1.add(Dense(units = 12, activation = 'relu'))\n",
        "model1.add(Dense(units = 6, activation = 'relu'))\n",
        "model1.add(Dense(units = 2, activation = 'softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "model1.compile(loss = 'categorical_crossentropy', optimizer = 'sgd')"
      ],
      "metadata": {
        "id": "1DYPCcAJj00e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above is the construction of the neural network, as we have 2000 points I think we can do a 5 split K fold cross validation and get good results so going to run that below in order to see what results the model gives and be able to work on improving it. This method is important to ensure that minimal overfitting is ocurring."
      ],
      "metadata": {
        "id": "QSszavOjxVe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up a k fold cross validation\n",
        "kf1 = KFold(n_splits = 5, shuffle = True)\n",
        "\n",
        "# Defining empty arrays to add our fraction values to so an average can be calculated at the end\n",
        "testfractions1 = 0\n",
        "trainfractions1 = 0\n",
        "\n",
        "for train_index, test_index in kf1.split(Inputs1):\n",
        "  TrainingInputs = Inputs1[train_index]\n",
        "  TrainingTargetHit = TargetHit1_binary[train_index]\n",
        "  TestInputs = Inputs1[test_index]\n",
        "  TestTargetHit = TargetHit1_binary[test_index]\n",
        "\n",
        "  # Use X_train, y_train to train the SVM\n",
        "  model1.fit(TrainingInputs, TrainingTargetHit, epochs = 10, batch_size = 40)\n",
        "  # Use svm.predict() to predict the output for the test data set\n",
        "  testresults = model1.predict(TestInputs)\n",
        "  # loop through to compare the test data output to what it should be and obtain the fraction of correct classifications\n",
        "  count = 0\n",
        "  for i in range(len(TestTargetHit[:,0])):\n",
        "    if (testresults[i, 0] > testresults[i, 1] and TestTargetHit[i, 0] > TestTargetHit[i, 1]) or (testresults[i, 0] < testresults[i, 1] and TestTargetHit[i, 0] < TestTargetHit[i, 1]):\n",
        "      count = count+1\n",
        "  testfractions1 = testfractions1 + (count / len(TestTargetHit[:,0]))\n",
        "  # Do the same prediction and assessment performance with the training data\n",
        "  count = 0\n",
        "  trainresults = model1.predict(TrainingInputs)\n",
        "  for i in range(len(TrainingTargetHit[:,0])):\n",
        "    if (trainresults[i, 0] > trainresults[i, 1] and TrainingTargetHit[i, 0] > TrainingTargetHit[i, 1]) or (trainresults[i, 0] < trainresults[i, 1] and TrainingTargetHit[i, 0] < TrainingTargetHit[i, 1]):\n",
        "      count = count+1\n",
        "  trainfractions1 = trainfractions1 + (count / len(TrainingTargetHit[:,0]))\n",
        "\n",
        "# Dividing the sum of 5 fraction values to get the average\n",
        "testfraction1 = testfractions1/5\n",
        "trainfraction1 = trainfractions1/5\n",
        "\n",
        "# Printing the final accuracy values\n",
        "print(testfraction1)\n",
        "print(trainfraction1)"
      ],
      "metadata": {
        "id": "7O7TO3YBzDk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd3ad1eb-9d68-4cba-926b-41464076719d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "40/40 [==============================] - 1s 2ms/step - loss: 0.7342\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6592\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6328\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.6116\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5905\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5689\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5476\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5267\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.5061\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.4861\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "50/50 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.4564\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.4374\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.4192\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.4024\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3864\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3716\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3582\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3456\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3345\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3240\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "50/50 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3246\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3165\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3097\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.3031\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2975\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2924\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2876\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2832\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2793\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2754\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "50/50 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2738\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2703\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2670\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2639\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2612\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2585\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2558\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2534\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2512\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2489\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "50/50 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2416\n",
            "Epoch 2/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2389\n",
            "Epoch 3/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2370\n",
            "Epoch 4/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2352\n",
            "Epoch 5/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2333\n",
            "Epoch 6/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2315\n",
            "Epoch 7/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2301\n",
            "Epoch 8/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2287\n",
            "Epoch 9/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2270\n",
            "Epoch 10/10\n",
            "40/40 [==============================] - 0s 2ms/step - loss: 0.2254\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "50/50 [==============================] - 0s 2ms/step\n",
            "0.8905\n",
            "0.88975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now model has been tested and proven out can export and run through the check script provided to check everything works and also get an idea of how accurate it is."
      ],
      "metadata": {
        "id": "4Dse4uv-1k9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the model\n",
        "model1.save('jg619-1.h5')\n",
        "\n",
        "# Saving the scaling parameters for temperature and strength\n",
        "scArray = np.array([[ArmLength1Mean, BallWeight1Mean, BallRadius1Mean, AirTemp1Mean, SpringConst1Mean, DeviceWeight1Mean], [ArmLength1std, BallWeight1std, BallRadius1std, AirTemp1std, SpringConst1std, DeviceWeight1std]])\n",
        "np.savetxt('jg619-1.txt', scArray)\n",
        "\n",
        "# Downloading the files\n",
        "from google.colab import files\n",
        "files.download('jg619-1.h5')\n",
        "files.download('jg619-1.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "VBVW-Fkw1uy0",
        "outputId": "819ddb3f-2a26-47da-c64a-0e4ef8cf5301"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4dc66a24-a606-4901-8105-ec98ac3b3b15\", \"jg619-1.h5\", 32832)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7b8d9d42-85ed-444e-bd52-f520ba149c3e\", \"jg619-1.txt\", 300)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above is all the code required for dataset 1, will copy the code blocks and replicate them below for dataset 2"
      ],
      "metadata": {
        "id": "K4r-P9QE7hd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start by importing the dataset\n",
        "dataset2 = pandas.read_csv('/content/dataset2.csv')\n",
        "\n",
        "# Write each column of the file to an array to make it easier to work with\n",
        "ArmLength2 = np.array(dataset2['Arm length (m)'][:])\n",
        "BallWeight2 = np.array(dataset2['Ball weight (kg)'][:])\n",
        "BallRadius2 = np.array(dataset2['Ball radius (mm)'][:])\n",
        "AirTemp2 = np.array(dataset2['Air temperature (deg C)'][:])\n",
        "SpringConst2 = np.array(dataset2['Spring constant (N per m)'][:])\n",
        "DeviceWeight2 = np.array(dataset2['Device weight (kg)'][:])\n",
        "TargetHit2 = np.array(dataset2['Target hit'][:])\n",
        "# Converting our currently 1D y values to 2D to match our model\n",
        "TargetHit2_binary = to_categorical(TargetHit2)\n",
        "\n",
        "# Going to scale each all of the data so want to find the mean and standard deviation\n",
        "ArmLength2Mean = np.mean(ArmLength2)\n",
        "ArmLength2std = np.std(ArmLength2)\n",
        "BallWeight2Mean = np.mean(BallWeight2)\n",
        "BallWeight2std = np.std(BallWeight2)\n",
        "BallRadius2Mean = np.mean(BallRadius2)\n",
        "BallRadius2std = np.std(BallRadius2)\n",
        "AirTemp2Mean = np.mean(AirTemp2)\n",
        "AirTemp2std = np.std(AirTemp2)\n",
        "SpringConst2Mean = np.mean(SpringConst2)\n",
        "SpringConst2std = np.std(SpringConst2)\n",
        "DeviceWeight2Mean = np.mean(DeviceWeight2)\n",
        "DeviceWeight2std = np.std(DeviceWeight2)\n",
        "\n",
        "# Finally creating the scaled arrays using these mean and std values\n",
        "ArmLength2Scaled = (ArmLength2 - ArmLength2Mean)/ArmLength2std\n",
        "BallWeight2Scaled = (BallWeight2 - BallWeight2Mean)/BallWeight2std\n",
        "BallRadius2Scaled = (BallRadius2 - BallRadius2Mean)/BallRadius2std\n",
        "AirTemp2Scaled = (AirTemp2 - AirTemp2Mean)/AirTemp2std\n",
        "SpringConst2Scaled = (SpringConst2 - SpringConst2Mean)/SpringConst2std\n",
        "DeviceWeight2Scaled = (DeviceWeight2 - DeviceWeight2Mean)/DeviceWeight2std\n",
        "\n",
        "# Finally forming these into one array to be parsed into the fit function\n",
        "Inputs2 = np.zeros((4000, 6))\n",
        "Inputs2[:,0] = ArmLength2Scaled\n",
        "Inputs2[:,1] = BallWeight2Scaled\n",
        "Inputs2[:,2] = BallRadius2Scaled\n",
        "Inputs2[:,3] = AirTemp2Scaled\n",
        "Inputs2[:,4] = SpringConst2Scaled\n",
        "Inputs2[:,5] = DeviceWeight2Scaled"
      ],
      "metadata": {
        "id": "74mRTuO17x8_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising our neural network\n",
        "model2 = Sequential()\n",
        "\n",
        "# Adding layers, these layers are two layers of 4 nodes using the ReLU function and 1 with 2 nodes using the softmax function\n",
        "model2.add(Dense(units = 10, activation = 'relu', input_dim = 6))\n",
        "model2.add(Dense(units = 12, activation = 'relu'))\n",
        "model2.add(Dense(units = 6, activation = 'relu'))\n",
        "model2.add(Dense(units = 2, activation = 'softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "model2.compile(loss = 'categorical_crossentropy', optimizer = 'sgd')"
      ],
      "metadata": {
        "id": "iML4EQrF8bGs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up a k fold cross validation\n",
        "kf2 = KFold(n_splits = 5, shuffle = True)\n",
        "\n",
        "# Defining empty arrays to add our fraction values to so an average can be calculated at the end\n",
        "testfractions2 = 0\n",
        "trainfractions2 = 0\n",
        "\n",
        "for train_index, test_index in kf2.split(Inputs2):\n",
        "  TrainingInputs = Inputs2[train_index]\n",
        "  TrainingTargetHit = TargetHit2_binary[train_index]\n",
        "  TestInputs = Inputs2[test_index]\n",
        "  TestTargetHit = TargetHit2_binary[test_index]\n",
        "\n",
        "  # Use X_train, y_train to train the SVM\n",
        "  model2.fit(TrainingInputs, TrainingTargetHit, epochs = 10, batch_size = 40)\n",
        "  # Use svm.predict() to predict the output for the test data set\n",
        "  testresults = model2.predict(TestInputs)\n",
        "  # loop through to compare the test data output to what it should be and obtain the fraction of correct classifications\n",
        "  count = 0\n",
        "  for i in range(len(TestTargetHit[:,0])):\n",
        "    if (testresults[i, 0] > testresults[i, 1] and TestTargetHit[i, 0] > TestTargetHit[i, 1]) or (testresults[i, 0] < testresults[i, 1] and TestTargetHit[i, 0] < TestTargetHit[i, 1]):\n",
        "      count = count+1\n",
        "  testfractions2 = testfractions2 + (count / len(TestTargetHit[:,0]))\n",
        "  # Do the same prediction and assessment performance with the training data\n",
        "  count = 0\n",
        "  trainresults = model1.predict(TrainingInputs)\n",
        "  for i in range(len(TrainingTargetHit[:,0])):\n",
        "    if (trainresults[i, 0] > trainresults[i, 1] and TrainingTargetHit[i, 0] > TrainingTargetHit[i, 1]) or (trainresults[i, 0] < trainresults[i, 1] and TrainingTargetHit[i, 0] < TrainingTargetHit[i, 1]):\n",
        "      count = count+1\n",
        "  trainfractions2 = trainfractions2 + (count / len(TrainingTargetHit[:,0]))\n",
        "\n",
        "# Dividing the sum of 5 fraction values to get the average\n",
        "testfraction2 = testfractions2/5\n",
        "trainfraction2 = trainfractions2/5\n",
        "\n",
        "# Printing the final accuracy values\n",
        "print(testfraction2)\n",
        "print(trainfraction2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOqWS0yp8f8U",
        "outputId": "dde05245-525a-40ba-9148-1aecd30651e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "80/80 [==============================] - 1s 2ms/step - loss: 0.6946\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6915\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6904\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6895\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6889\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6884\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6879\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6874\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6870\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6864\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6864\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6857\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6853\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6847\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6842\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6836\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6832\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 0s 3ms/step - loss: 0.6826\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6822\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6815\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6833\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6828\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6822\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6816\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6811\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6805\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6798\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6792\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6784\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6777\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6737\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6725\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6717\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6707\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6699\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6689\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6681\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6671\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6661\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6652\n",
            "25/25 [==============================] - 0s 2ms/step\n",
            "100/100 [==============================] - 0s 1ms/step\n",
            "Epoch 1/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6670\n",
            "Epoch 2/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6663\n",
            "Epoch 3/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6655\n",
            "Epoch 4/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6647\n",
            "Epoch 5/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6640\n",
            "Epoch 6/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6633\n",
            "Epoch 7/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6624\n",
            "Epoch 8/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6617\n",
            "Epoch 9/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6609\n",
            "Epoch 10/10\n",
            "80/80 [==============================] - 0s 2ms/step - loss: 0.6601\n",
            "25/25 [==============================] - 0s 1ms/step\n",
            "100/100 [==============================] - 0s 2ms/step\n",
            "0.5885\n",
            "0.5744999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exporting the model\n",
        "model2.save('jg619-2.h5')\n",
        "\n",
        "# Saving the scaling parameters for temperature and strength\n",
        "scArray = np.array([[ArmLength2Mean, BallWeight2Mean, BallRadius2Mean, AirTemp2Mean, SpringConst2Mean, DeviceWeight2Mean], [ArmLength2std, BallWeight2std, BallRadius2std, AirTemp2std, SpringConst2std, DeviceWeight2std]])\n",
        "np.savetxt('jg619-2.txt', scArray)\n",
        "\n",
        "# Downloading the files\n",
        "from google.colab import files\n",
        "files.download('jg619-2.h5')\n",
        "files.download('jg619-2.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "YTG_f25d9NCE",
        "outputId": "9170404e-4b62-4e35-8212-3f5beee11446"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a9af6d02-c1e5-4ccb-994f-0a8b164b3755\", \"jg619-2.h5\", 32832)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0aa018c1-4bd0-4021-b12d-2a2549916ba7\", \"jg619-2.txt\", 300)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}